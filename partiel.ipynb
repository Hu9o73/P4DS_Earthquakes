{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert-block alert-info'>\n",
    "    <br>\n",
    "    <h1 align=\"center\"><b>  Programming in data science :</b> Final Project </h1>\n",
    "    <h3 align=\"center\">Earthquake dataset </h3>\n",
    "    <h5 align=\"center\">BONNELL Hugo - HAMADEH Rayan - BLANCHET Lucas - AFFES Nour - MAARBANI Yasmine - BRUN Pierre-Louis</a></h5>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plotly import express as px\n",
    "\n",
    "# ARIMA : Library used in a green AI project to forecast, reusing it here\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv(filePath):\n",
    "    \"\"\"\n",
    "    Function for reading a CSV file\n",
    "\n",
    "    Input: filePath <string> : The path to the CSV file.\n",
    "\n",
    "    Returns : data <pd.DataFrame> : The data as a pandas' dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    return pd.read_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows and columns\n",
    "\n",
    "def EDA(data):\n",
    "    \"\"\"\n",
    "    This function aims to help explore the dataset\n",
    "    \n",
    "    Parameters: data <pandas.DataFrame> : dataset we're studying.\n",
    "\n",
    "    Returns: None\n",
    "\n",
    "    Prints: \n",
    "        1 - number of columns and rows\n",
    "        2 - data type in each column\n",
    "        3 - number of missing data per column\n",
    "        4 - correlation between variables\n",
    "    \"\"\"\n",
    "    row, col = data.shape\n",
    "    print(\"The dataset has : \", row, \" rows and \", col ,\" columns.\")\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n--------------------------------\\n\\n\")\n",
    "    print(\"Data Information : \")\n",
    "    print(data.info())\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n--------------------------------\\n\\n\")\n",
    "    print(\"Number of null per column:\")\n",
    "    print(data.isna().sum())\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n--------------------------------\\n\\n\")\n",
    "    print(\"Correlation matrix:\")\n",
    "\n",
    "    # Compute the correlation matrix \n",
    "    data['Location_Name_Encoded'] = LabelEncoder().fit_transform(data['Location Name'])\n",
    "\n",
    "    corr_matrix = data.drop(columns=['Location Name']).corr(method='pearson')\n",
    "\n",
    "    # Plot the correlation matrix as a heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=False, fmt='.2f', cmap='coolwarm', cbar=True, square=True)\n",
    "    plt.title(\"Correlation Matrix (Pearson Method)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    data.drop(columns=['Location_Name_Encoded'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_magnitude_by_year(data):\n",
    "    \"\"\"\n",
    "    Finds the maximum earthquake magnitude for each year.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The earthquake dataset containing 'Year' and 'Mag' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame showing the maximum magnitude per year.\n",
    "    \"\"\"\n",
    "    result = data.groupby('Year')['Mag'].max().reset_index()\n",
    "    result.columns = ['Year', 'Max_Magnitude']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earthquakes_by_location(data):\n",
    "    \"\"\"\n",
    "    Counts the total number of earthquakes for each location.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The earthquake dataset containing 'Location Name'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A summary DataFrame showing the total earthquakes per location.\n",
    "    \"\"\"\n",
    "    result = data['Location Name'].value_counts().reset_index()\n",
    "    result.columns = ['Location', 'Total_Earthquakes']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_distribution(data):\n",
    "    \"\"\"\n",
    "    Extracts the month from 'Mo' column and counts earthquakes per month.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The dataset containing 'Mo' column.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A summary of earthquakes by month.\n",
    "    \"\"\"\n",
    "    result = data['Mo'].value_counts().sort_index().reset_index()\n",
    "    result.columns = ['Month', 'Total_Earthquakes']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_depth_by_magnitude(data):\n",
    "    \"\"\"\n",
    "    Groups earthquakes into magnitude ranges and calculates the average focal depth.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The dataset containing 'Mag' and 'Focal Depth (km)' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame showing the average focal depth for each magnitude range.\n",
    "    \"\"\"\n",
    "    bins = [0, 4, 6, 8, 10]  # Magnitude ranges\n",
    "    labels = ['0-4', '4-6', '6-8', '8-10']\n",
    "    \n",
    "    # Create magnitude categories\n",
    "    data['Magnitude_Range'] = pd.cut(data['Mag'], bins=bins, labels=labels)\n",
    "    \n",
    "    # Group by magnitude range and calculate the average focal depth\n",
    "    result = data.groupby('Magnitude_Range')['Focal Depth (km)'].mean().reset_index()\n",
    "    result.columns = ['Magnitude_Range', 'Avg_Focal_Depth']\n",
    "    data.drop(columns=['Magnitude_Range'], inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_magnitude(data):\n",
    "    \"\"\"\n",
    "    Discretizes the earthquake magnitude into categories (Low, Medium, High, Extreme) \n",
    "    and plots them with specific colors.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The earthquake dataset containing the 'Mag' column.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with an additional 'Magnitude_Category' column.\n",
    "    \"\"\"\n",
    "    # Define magnitude bins and labels\n",
    "    bins = [0, 4, 6, 7, 10]  # Magnitude ranges\n",
    "    labels = ['Low', 'Medium', 'High', 'Extreme']\n",
    "\n",
    "    # Discretize 'Mag' into categories\n",
    "    data['Magnitude_Category'] = pd.cut(data['Mag'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "    return data['Magnitude_Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_magnitude(data):\n",
    "    \"\"\"\n",
    "    Standardizes the earthquake magnitude using Z-score normalization.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The earthquake dataset containing the 'Mag' column.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with an additional column for normalized magnitudes.\n",
    "    \"\"\"\n",
    "    # Copy the data to avoid modifying the original DataFrame\n",
    "    data_copy = data.copy()\n",
    "\n",
    "    # Apply Z-score normalization to the 'Mag' column\n",
    "    data_copy['Mag_Zscore'] = zscore(data_copy['Mag'], nan_policy='omit')\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_earthquake_hotspots(data, eps=2, min_samples=10):\n",
    "    \"\"\"\n",
    "    Detects earthquake hotspots using DBSCAN clustering.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): Earthquake dataset containing 'Latitude' and 'Longitude'.\n",
    "    eps (float): The maximum distance between two samples for clustering.\n",
    "    min_samples (int): The number of samples in a cluster.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays a scatter plot of earthquake clusters.\n",
    "    \"\"\"\n",
    "    # Step 1: Extract spatial data (latitude and longitude)\n",
    "    spatial_data = data[['Latitude', 'Longitude']].dropna()\n",
    "\n",
    "    # Step 2: Apply DBSCAN clustering\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    spatial_data['Cluster'] = dbscan.fit_predict(spatial_data)\n",
    "\n",
    "    # Step 3: Visualize the clusters\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(spatial_data['Longitude'], spatial_data['Latitude'], \n",
    "                c=spatial_data['Cluster'], cmap='rainbow', s=10, alpha=0.7)\n",
    "    plt.title(\"Earthquake Hotspots Detected Using DBSCAN\")\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.colorbar(label=\"Cluster\")\n",
    "\n",
    "    # Display cluster information\n",
    "    print(\"Number of clusters (excluding noise):\", len(set(spatial_data['Cluster'])) - (1 if -1 in spatial_data['Cluster'] else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_earthquake_map(data):\n",
    "    \"\"\"\n",
    "    Generate a scatter mapbox plot for earthquakes based on latitude, longitude, magnitude, and focal depth.\n",
    "    \n",
    "    Parameters:\n",
    "    data (pd.DataFrame): DataFrame containing 'Latitude', 'Longitude', 'Mag', and 'Focal Depth (km)' columns.\n",
    "    \n",
    "    Returns:\n",
    "    plotly.graph_objects.Figure: A Plotly scatter mapbox figure.\n",
    "    \"\"\"\n",
    "    emap = px.scatter_mapbox(\n",
    "        data[[\"Latitude\", \"Longitude\", \"Mag\", \"Focal Depth (km)\"]].dropna(),\n",
    "        lat=\"Latitude\",\n",
    "        lon=\"Longitude\",\n",
    "        color=\"Mag\",\n",
    "        size=\"Focal Depth (km)\",\n",
    "        color_continuous_scale=px.colors.cyclical.IceFire,\n",
    "        size_max=20,\n",
    "        zoom=3  # Adjust zoom level for better visibility\n",
    "    )\n",
    "    emap.update_layout(mapbox_style=\"carto-positron\")\n",
    "    emap.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    return emap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_earthquakes(data, future_years=5):\n",
    "    \"\"\"\n",
    "    Forecasts the number of earthquakes per year using ARIMA.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): Earthquake dataset containing 'Year'.\n",
    "    future_years (int): Number of future years to forecast.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Forecasted number of earthquakes.\n",
    "    \"\"\"\n",
    "    # Step 1: Count earthquakes per year\n",
    "    earthquakes_per_year = data['Year'].dropna().astype(int).value_counts().sort_index()\n",
    "    earthquakes_series = earthquakes_per_year.reindex(range(earthquakes_per_year.index.min(), \n",
    "                                                             earthquakes_per_year.index.max() + 1), \n",
    "                                                      fill_value=0)\n",
    "\n",
    "    # Step 2: Build and fit ARIMA model\n",
    "    model = ARIMA(earthquakes_series, order=(2, 1, 1))  # ARIMA parameters can be tuned\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Step 3: Forecast for future years\n",
    "    forecast = model_fit.forecast(steps=future_years)\n",
    "\n",
    "    # Combine historical and forecasted data\n",
    "    future_index = range(earthquakes_series.index.max() + 1, earthquakes_series.index.max() + 1 + future_years)\n",
    "    forecast_df = pd.DataFrame({'Year': future_index, 'Forecasted_Earthquakes': forecast.values})\n",
    "\n",
    "    return forecast_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function():\n",
    "\n",
    "    # Exploratory data Analysis    \n",
    "    data = import_csv('earthquakes.csv')\n",
    "    EDA(data)\n",
    "\n",
    "\n",
    "    max_magnitude = max_magnitude_by_year(data)\n",
    "    max_magnitude['Moving_Avg'] = max_magnitude['Max_Magnitude'].rolling(window=20).mean()\n",
    "\n",
    "    fig1 = go.Figure(go.Scatter(x=max_magnitude['Year'], y=max_magnitude['Moving_Avg'], mode='lines', name=\"Max Magnitude\"))\n",
    "    fig1.update_layout(title=\"Average Max Magnitude per year\", xaxis_title=\"Year\", yaxis_title=\"Max Magnitude\", xaxis=dict(range=[0, 2020]))\n",
    "    \n",
    "\n",
    "    monthly_earthquakes = monthly_distribution(data)\n",
    "    fig2 = go.Figure(go.Bar(x=monthly_earthquakes['Month'], y=monthly_earthquakes['Total_Earthquakes'], name=\"Monthly Earthquakes\"))\n",
    "    fig2.update_layout(title=\"Number of Earthquakes per Month\", xaxis_title=\"Month\", yaxis_title=\"Total Earthquakes\")\n",
    "\n",
    "    \n",
    "    discretized_data = discretize_magnitude(data)\n",
    "    discretized_counts = discretized_data.value_counts().sort_index()\n",
    "    fig3 = go.Figure(go.Bar(x=discretized_counts.index, y=discretized_counts.values, name=\"Earthquakes Categories\"))\n",
    "    fig3.update_layout(title=\"Number of Earthquakes per Category\", xaxis_title=\"Category\", yaxis_title=\"Number of Earthquakes\")\n",
    "\n",
    "\n",
    "    normalized_data = normalize_magnitude(data)\n",
    "    normalized_data_counts = normalized_data[\"Mag_Zscore\"].value_counts().sort_index()\n",
    "    fig4 = go.Figure(go.Bar(x=normalized_data_counts.index, y=normalized_data_counts.values, name=\"Normalized Mags\"))\n",
    "    fig4.update_layout(title=\"Normalized (Zscore) Magnitude\", xaxis_title=\"Magnitude's ZScore\", yaxis_title=\"Count\")\n",
    "\n",
    "    forecasted_earthquakes = forecast_earthquakes(data, future_years=5)\n",
    "    fig5 = go.Figure(go.Bar(x=forecasted_earthquakes['Year'], y=forecasted_earthquakes['Forecasted_Earthquakes'], name='Normalized Mags'))\n",
    "    fig5.update_layout(title=\"Earthquakes ARIMA Forecast\", xaxis_title=\"Year\", yaxis_title=\"Forecasted Earthquakes\", yaxis=dict(range=[40, 55]))\n",
    "\n",
    "    emap = generate_earthquake_map(data)\n",
    "\n",
    "    dashboard_creator(fig1, fig2, fig3, fig4, fig5, emap)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def dashboard_creator(fig1, fig2, fig3, fig4, fig5, emap):\n",
    "    \n",
    "    # Initialize the Dash app\n",
    "    app = dash.Dash(__name__)\n",
    "\n",
    "    # Dataset and Team Info\n",
    "    dataset_name = \"Earthquake Dataset\"\n",
    "    team_members = [\"BONNELL Hugo\", \"HAMADEH Rayan\", \"BLANCHET Lucas\", \"AFFES Nour\", \"MAARBANI Yasmine\", \"BRUN Pierre-Louis\"]\n",
    "\n",
    "    # Layout for Dash App\n",
    "    app.layout = html.Div([\n",
    "        # Header Section\n",
    "        html.Div([\n",
    "            html.H1(\"Earthquake Metrics Dashboard\"),\n",
    "            html.H3(f\"Dataset: {dataset_name}\"),\n",
    "            html.H4(f\"Team Members: {', '.join(team_members)}\")\n",
    "        ], style={'textAlign': 'center', 'marginBottom': '20px'}),\n",
    "        \n",
    "        # Metric Visualizations\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                dcc.Graph(figure=fig1)\n",
    "            ], className='six columns'),\n",
    "            html.Div([\n",
    "                dcc.Graph(figure=fig2)\n",
    "            ], className='six columns'),\n",
    "        ], className='row'),\n",
    "        \n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                dcc.Graph(figure=fig3)\n",
    "            ], className='six columns'),\n",
    "            html.Div([\n",
    "                dcc.Graph(figure=fig4)\n",
    "            ], className='six columns'),\n",
    "        ], className='row'),\n",
    "\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                dcc.Graph(figure=fig5)\n",
    "            ], className='six columns')\n",
    "        ], className='row'),\n",
    "\n",
    "        html.Div([\n",
    "        dcc.Graph(\n",
    "            id='earthquake-map',\n",
    "            figure=emap\n",
    "        )], style={'marginTop': '20px'})\n",
    "\n",
    "    ], style={'margin': '20px'})\n",
    "\n",
    "\n",
    "    app.run_server(debug=True)\n",
    "\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1d69831df50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the app\n",
    "if __name__ == \"__main__\":\n",
    "    main_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "So from the EDA function we can see that:\n",
    "- Our data set is of shape 4424x38.\n",
    "\n",
    "- All of our columns are of time float except for the 'Location Name' column which contains an object (string) (which we encoded into an integer just for the correlation matrix so that we can study it as well).\n",
    "\n",
    "- We have a significant issue regarding the null values in our columns which might pause problems later on.\n",
    "\n",
    "- Correlation Matrix:\n",
    "  - Recap about what correlation matrix helps with:\n",
    "    A correlation matrix shows the pairwise relationships (correlations) between numerical variables in a dataset.\n",
    "\n",
    "    Values range from -1 to 1:\n",
    "        +1: Perfect positive correlation (both variables increase together).\n",
    "        -1: Perfect negative correlation (one increases while the other decreases).\n",
    "        0: No correlation (the variables are independent)\n",
    "        \n",
    "  - Key observations:\n",
    "    - Variables like **Deaths**, **Total Deaths**, and **Death Description** are highly correlated, which makes perfect sense.\n",
    "    - **Houses Destroyed** and **Total Houses Distroyed** are also highly correlated.\n",
    "\n",
    "    - Negative correlation present between **Focal Depth** and **Damage** which helps us understand that if the focal depth increases, the damage decreases due to deeper quakes having less impact on the surface.\n",
    "\n",
    "    - **Latitude** and **Temperature** are negatively correlated as well, which means higher latitudes (locations closer to the poles) are associated with lower temperatures.\n",
    "\n",
    "\n",
    "### max_maggnitude_by_year\n",
    "So what this function does is plot a line graph of the maximum magnitude per year.\n",
    "\n",
    "We were obliged to apply a moving average (rolling window of 20) so that our graph is actually readable.\n",
    "\n",
    "Observing the graph, there is a noticeable upward trend in the maximum earthquake magntiudes over time. This trend is especially noticeable about 1500 and onwards, reaching an alltime high in our last year recorded in our dataset at hand (2020).\n",
    "\n",
    "This could indicate one of two results:\n",
    "- Increase in the severity of earthquakes with time.\n",
    "- Improvements in seismic measurement technologies and methods, allowing for more frequent and accurate earthquake recordings, which is apparent even by how smooth the graph is in early years, where not nearly as much data was recorded as recent years.\n",
    "\n",
    "\n",
    "## Indicators analysis\n",
    "\n",
    "### earthquakes_by_location\n",
    "This function shows us the top 20 locations in terms of earthquake frequency regardless of earthquake intensity or magnitude. What's obvious here is that China is encountering a lot of earthquakes with Yunnan Province being the most eathquake-prone location in all our dataset.\n",
    "\n",
    "### monthly_distribution\n",
    "Here, we display the frequency of earthquakes per month with month 0 being January and 11 being December.\n",
    "\n",
    "The bar chart shows a consistent distribution of earthquake occurences, with monthly counts ranging between 300 and 380. This indicates that earthquake activity doesn't exhibit a clear seasonal pattern, suggesting the need for year-round preparation and expectation of earthquakes.\n",
    "\n",
    "### average_depth_by_magnitude\n",
    "This function groups earthquakes into 4 bins according to magnitude range and shows the average focal depth for each magnitude range.\n",
    "\n",
    "As the correlation matrix showed us, we can see a negative correlation between focal length and earthquake magnitude indicating that as the focal depth decreases, the magnitude increases\n",
    "\n",
    "### discretize_magnitude\n",
    "In discretize_magnitude, we create bins, almost like what we did in the above function, and compare the count of each category of earthquake.\n",
    "\n",
    "What we could observe was that:\n",
    "- The count of earthquake is significantly higher for medium, high, and extreme categories, and a significantly low for the \"low category\".\n",
    "- This distribution indicates that while low magnitude earthquakes are rare in this dataset, medium to extremely powerful earthquakes occur more frequently which is not typical.\n",
    "- This is due to the fact that our dataset only focuses on important (high magnitude) earthquakes.\n",
    "\n",
    "### normalize_magnitude\n",
    "Z-Score Normalization: the magnitude data is normalized using Z-score method where we adjust the values to have a mean of 0 and a standard deviation of 1, transforming each value to represent its distance from the mean in terms of standard deviations.\n",
    "\n",
    "Identifying Extreme Events: eathquakes with a Z-score above 2 are considered extreme.\n",
    "\n",
    "The histogram displays a bell-shaped curve centered around zero, which is typical for Z-score normalized data. The data skews slightly to the right (positive side) indicating a few extreme positive occurences (higher magnitude extreme earthquakes).\n",
    "\n",
    "\n",
    "## Geodata Analysis\n",
    "\n",
    "The graphs show earthquake hotspots around the globe. The graphs identify specific regions with a high density of earthquakes, such as: \n",
    "- Pacific Ring of Fire (pacific coasts of Asia and the Americas)\n",
    "- Mid-Atlantic Ridge\n",
    "- South-East Asia RÃ©gions. \n",
    "  \n",
    "They also show sparce earthquake regions that are either outliers or less prone to earthquake activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
